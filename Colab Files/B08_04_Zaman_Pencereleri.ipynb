{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B08_04_Zaman_Pencereleri.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGNXO-FWlfKX"
      },
      "source": [
        "# Zaman Pencereleri (Time Windows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Pp7DsfovGc"
      },
      "source": [
        "Bu colab dosyasında bir zaman serisis makine öğrenmesi modellerini eğitmek için kullanabileceğimiz bir biçime nasıl dönüştüreceğimize bakacağız.\n",
        "\n",
        "Bunun için elbette `tensorflow` paketlerinden faydalanacağız. TensorFlow'u içeri aktararak başlayalım.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a89oLmflZCC"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMrEoRJ6o8kx"
      },
      "source": [
        "Önceki 20 adımda verileri bir sonraki adımı tahmin etmek için bir model eğiteceğiz. Bu nedenle eğitim için 20 adımlk pencerelerden oluşan bir veri seti oluşturmamız gerekiyor.\n",
        "\n",
        "Ama öncelikle, sıfırdan dokuza kadar sayılar içeren bir veri kümesi oluşturalım."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnCHstgipje4",
        "outputId": "92eb2ca2-bdee-4557-bc45-fad9bc7b2829"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "for val in dataset:\n",
        "    print(val)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Tai-3yprNE"
      },
      "source": [
        "Toplam 10 tane tensör oluşturdul. `numpy()` işlevi ile bu tensörlerin sadece değerlerini alalım."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Yzv08rpknJ",
        "outputId": "05c22c15-0853-4e6e-ca03-7c257eebfa34"
      },
      "source": [
        "for val in dataset:\n",
        "    print(val.numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6852WebRp5W6"
      },
      "source": [
        "Oldukça iyi. Sırada `windows` metodunu çağıralım. Pencere boyutu olarak `5` değerini veriyoruz. Kaydırma değerimizi (`shift`) değerimizi `1` olarak atıyoruz. Bu sayede her pencere, önceki pencereye kıyasla bir zaman dilimi (adımı) kaydırılmış olur. `end = \" \"` parametresi sayesinde bir pencerenin tamamı yazdırılmadan bir alt satıra inmesine engel oluyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlk-FMyhp1Gy",
        "outputId": "350169da-5407-493e-e9c2-7cdf310081dd"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1)\n",
        "for window_dataset in dataset:\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end=\" \")\n",
        "    print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "6 7 8 9 \n",
            "7 8 9 \n",
            "8 9 \n",
            "9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKSIi2tRqcI2"
      },
      "source": [
        "Çıktılara baktığımızda son birkaç pencerenin diğer pencerelerden daha kısa olduğunu fark ediyoruz. Bunun sebebi zaman serisinin sonuna gelmemizdir. Makine öğrenmesi modelleri genellikle sabit boyutlu girdiler bekleyeceği için bu durumu düzeltmek için `drop_remainder = True` parametresini veriyoruz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4VRtWnEqaYr",
        "outputId": "d0f48b1d-d2a2-4c04-b97d-9f0750301293"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "for window_dataset in dataset:\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end=\" \")\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWYh73l6q4Lh"
      },
      "source": [
        "Şuana kadar oldukça iyi gidiyoruz. Ancak, sahip olmak istediğimiz şey düzenli tensörler biçiminde veri yığınları içeren tek bir veri kümesidir. Bu durum için `flap_map` metodu yardımcı olacaktır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRHxvjjyqy9D",
        "outputId": "42d7af1e-7d0e-4ca2-a195-308c8a8acb8f"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for window in dataset:\n",
        "    print(window.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p90LbmfVrJ5w"
      },
      "source": [
        "Oldukça güzel, hedeflediğimiz şeyi başardık gibi görünüyor.\n",
        "\n",
        "Makine öğrenmesi modelleri genellikle girdi özelliklerine ve **etiketlerine** sahip olmak ister. Bunu yapmak için `flat_map` metodundan hemen sonra bir `map` metodu kullanabiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV4-K2QArIIR",
        "outputId": "ea737f07-35da-4a11-e011-c7e0e29233e2"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "for x, y in dataset:\n",
        "    print(x.numpy(), y.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8sydiGWrhd0"
      },
      "source": [
        "4 girdi ve 1 çıktı etiketi olarak tüm pencereleri parçaladık. Bununla beraber örneklerin sırasını rasgele karıştırmamız gereklidir bunu yaparsak makine öğrenmesi modelimiz sırayla ilgili yanlış bir öğrenme yapmamış olur. `shuffle` metodunu kullanarak pencereleri karıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP0p-ji6rfx6",
        "outputId": "4d909cd2-c565-4453-e883-ecccba4a5046"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "for x, y in dataset:\n",
        "    print(x.numpy(), y.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 4 5 6] [7]\n",
            "[2 3 4 5] [6]\n",
            "[1 2 3 4] [5]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n",
            "[0 1 2 3] [4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WskkXGiDr7-u"
      },
      "source": [
        "Gruplama yapmak büyük seriler ile çalışırken faydalı olacaktır. Böylelikle TensorFlow mevcut girdi ile çalışırken aynı zamanda sıradaki girdiyi yükleyebilir. Bu da işlemcimizin boş beklemeden kurtarmış olacaktır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZYbGPegr19i",
        "outputId": "ca46a215-7d5e-48e7-8e05-591e1e5313b7"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "for x, y in dataset:\n",
        "    print(\"x =\", x.numpy())\n",
        "    print(\"y =\", y.numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [[0 1 2 3]\n",
            " [2 3 4 5]]\n",
            "y = [[4]\n",
            " [6]]\n",
            "x = [[4 5 6 7]\n",
            " [1 2 3 4]]\n",
            "y = [[8]\n",
            " [5]]\n",
            "x = [[3 4 5 6]\n",
            " [5 6 7 8]]\n",
            "y = [[7]\n",
            " [9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9JsQEcPsOhm"
      },
      "source": [
        "Tüm bu adımları bir araya getirelim ve sonraki colab dosyalarında kullanmak üzere bir fonksiyon tanımlayalım:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpFI-MIysNua"
      },
      "source": [
        "def window_dataset(series, window_size, batch_size=32,\n",
        "                   shuffle_buffer=1000):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}